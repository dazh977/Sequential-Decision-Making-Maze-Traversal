# Sequential-Decision-Making-Maze-Traversal

Implementation: policy iteration with a known model, model-free off-policy Q learning and model-free on-policy SARSA algorithm. All in discrete case. Utilized broadcasting and vectorization of 6-dimensional Numpy arrays to acclerate calculation of state values. Highest reward (close to 0) - shortest path from start to goal
